# REWARDS ULTRA-SPARSE - L'agent apprend par lui-même
# Philosophy: Seulement goal/loss + RND curiosity

# ========== GOALS SEULEMENT ==========
goal_scored: 100.0
goal_conceded: -10.0
own_goal: -50.0

# ========== WIN/DRAW/LOSS ==========
win_bonus: 10.0
draw_bonus: 0.0
loss_penalty: -5.0

# ========== GUIDANCE MINIMALE (pour bootstrapping) ==========
# Problème: Sans AUCUN goal sur millions de steps, agent optimise RND uniquement
# Solution: Guidance TRÈS FAIBLE juste pour orienter vers but adverse

ball_possession:
  enabled: false
  
player_movement:
  enabled: false
  
goal_distance:
  enabled: true
  reward_scale: 0.01  # TRÈS FAIBLE: juste pour orienter
  normalize: true
  
shot_any:
  enabled: true
  base_reward: 2.0    # Petit bonus pour tirer (apprendre l'action SHOT)
  cooldown_steps: 10
  
shot_attempt:
  enabled: false
  
shot_on_target:
  enabled: false
  
successful_pass:
  enabled: false

pass_under_pressure_bonus:
  enabled: false

ball_recovery:
  enabled: false
  
ball_lost:
  enabled: false
  
successful_tackle:
  enabled: false
  
dribble_progress:
  enabled: false

penalty_box_bonus:
  enabled: false
  
dangerous_shot_penalty:
  enabled: false

dangerous_pass_penalty:
  enabled: false

approach_own_goal_penalty:
  enabled: true
  danger_zone_x: -0.6  # Pénalité si x < -0.6 (proche de notre but)
  reward: -5.0  # Malus pour décourager CSC

backward_movement_penalty:
  enabled: false

out_of_bounds:
  enabled: false
  
yellow_card:
  enabled: false
  
red_card:
  enabled: false
  
sideline_penalty:
  enabled: false

time_penalty:
  enabled: false
  
# ========== SHAPING DÉSACTIVÉ ==========
shaping:
  enabled: false
  start_weight: 1.0
  end_weight: 1.0
  anneal_steps: 50000000

# ========== NORMALIZATION ==========
normalize_rewards: false
clip_rewards: false
