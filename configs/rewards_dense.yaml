# REWARDS STANDARDS ACAD√âMIQUES - Approche √©quilibr√©e
# Philosophy: Goal reward >> Shaping rewards (ratio 10:1 minimum)

# ========== GOALS (DOMINANT SIGNAL) ==========
goal_scored: 100.0         # DOMINANT (acad√©mique: 20-100)
goal_conceded: -10.0       # Mod√©r√©
own_goal: -50.0           # Fort pour CSC

# ========== BALL POSSESSION ==========
ball_possession:
  enabled: false  # D√©sactiv√©: cr√©e optimum local
  reward_per_step: 0.0
  
# ========== PLAYER MOVEMENT (D√âSACTIV√â: trop complexe) ==========
player_movement:
  enabled: false
  forward_bonus: 0.0
  idle_penalty: 0.0

# ========== GOAL DISTANCE (guidance SIMPLE vers but) ==========
goal_distance:
  enabled: true
  reward_scale: 1.0      # SIMPLE: guidance basique
  normalize: true
  
# ========== SHOT ANY (feedback basique pour tirer) ==========
shot_any:
  enabled: false
  base_reward: 2.0       # Mod√©r√©: encourage tir
  possession_bonus: 2.0  # +2 si possession
  offensive_bonus: 3.0   # +3 si zone offensive (x>0.5)
  cooldown_steps: 10

# ========== SHOT ATTEMPTS (conditions ULTRA-RELAX√âES) ==========
shot_attempt:
  enabled: true
  reward: 10.0   # FORT pour encourager tir
  require_possession: false
  min_x_position: 0.0  # N'importe o√π
  max_y_distance: 1.0  # N'importe o√π
  max_distance_from_goal: 10.0  # N'importe o√π
  cooldown_steps: 10
  
shot_on_target:
  enabled: false         # D√âSACTIV√â: GRF ne fournit pas cette info
  reward: 0.0
  
# ========== PASS (encourage les passes) ==========
successful_pass:
  enabled: true
  reward: 0.08           # Acad√©mique: 0.05-0.1
  min_distance: 0.1
  min_x_progress: 0.05
  cooldown_steps: 5
pass_under_pressure_bonus:
  enabled: true
  reward: 0.15           # Acad√©mique: 0.1-0.2
pressure_distance: 0.15
  
# ========== TACKLE/INTERCEPTION (d√©fense) ==========
ball_recovery:
  enabled: true
  reward: 0.1            # Subtil (sera anneal√©)
  
ball_lost:
  enabled: true
  reward: -0.3           # P√©nalit√© base
  danger_zone_penalty: -0.5  # Extra si x < -0.6 (zone d√©fensive)
  attacking_zone_penalty: -0.2  # Extra si x > 0.5 (perd en attaquant)
  
successful_tackle:
  enabled: true
  reward: 0.2            # Mod√©r√©
  
# ========== DRIBBLE (progression avec ballon) ==========
dribble_progress:
  enabled: false  # D√©sactiv√©: redondant avec goal_distance
  reward_scale: 0.0

# ========== PENALTY BOX (milestone bonus) ==========
penalty_box_bonus:
  enabled: true
  reward_on_entry: 20.0  # TR√àS FORT
  reward_per_step: 0.0
  min_x: 0.7
  require_possession: true
  
# ========== PENALTIES ANTI-CSC (PRIORIT√â ABSOLUE) ==========
# üî• MALUS pour actions dangereuses EN ZONE DANGEREUSE UNIQUEMENT (x < -0.6)
# √âquipe attaque vers x=+1, d√©fend x=-1

dangerous_shot_penalty:
  enabled: true
  reward: -20.0          # üî• FORT : Tir vers son propre but = tr√®s mauvais
  danger_zone_x: -0.6    # Zone dangereuse (proche de notre but)
  angle_threshold: 0.7   # Dot product: direction vers propre but (cos > 0.7 ‚âà 45¬∞)

dangerous_pass_penalty:
  enabled: false  # D√âSACTIV√â: passe arri√®re peut √™tre strat√©gique en 3v1
  reward: -15.0
  danger_zone_x: -0.6

approach_own_goal_penalty:
  enabled: false  # D√âSACTIV√â: cause rewards -50 en 3v1 (adversaire contre-attaque)
  reward: -10.0
  danger_zone_x: -0.6

backward_movement_penalty:
  enabled: false         # D√âSACTIV√â : redondant avec approach_own_goal_penalty
  reward: -5.0
  
sideline_penalty:
  enabled: false  # D√âSACTIV√â: contribution mineure mais √©vite rewards n√©gatifs
  reward: -0.02
  y_threshold: 0.38

# ========== PENALTIES (√©viter comportements stupides) ==========
out_of_bounds:
  enabled: true
  penalty: -100.0  # CATASTROPHIQUE: doit absolument √©viter!
  x_max: 1.01
  x_min: -1.0
  y_max: 0.42
  
yellow_card:
  enabled: true
  penalty: -0.5
  
red_card:
  enabled: true
  penalty: -2.0
  
# ========== TIME PENALTY (D√âSACTIV√â: trop subtil) ==========
time_penalty:
  enabled: false
  penalty_per_step: 0.0
  
# ========== SHAPING (D√âSACTIV√â pour apprentissage rapide) ==========
shaping:
  enabled: false  # D√âSACTIV√â: pas d'annealing, multiplier = 1.0 constant
  start_weight: 1.0
  end_weight: 1.0  # Pas d'annealing
  anneal_steps: 50000000  # Tr√®s lent (50M steps)
  
# ========== WIN/DRAW/LOSS (sparse) ==========
win_bonus: 5.0           # Augment√© pour renforcer signal
draw_bonus: 0.0
loss_penalty: 0.0  # Pas de p√©nalit√© (d√©j√† -goal_conceded)

# ========== NORMALIZATION ==========
normalize_rewards: true
clip_rewards: true
clip_range: [-100.0, 100.0]  # Coh√©rent avec goal_scored = 100.0